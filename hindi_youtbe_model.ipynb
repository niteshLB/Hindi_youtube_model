{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9mbfnw1bLhO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from pytube import YouTube\n",
        "from moviepy.editor import VideoFileClip\n",
        "from transformers import pipeline,T5Tokenizer,T5ForConditionalGeneration\n",
        "import torchaudio\n",
        "from torchaudio.transforms import Resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRbbk1ikbQRF",
        "outputId": "f7dee386-fd25-4575-b0f0-1528290e05c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/57.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m997.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhw3r8YUbXqt",
        "outputId": "3a59adc2-dbbc-4759-c636-ce692243809f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdYf_ogSblGX"
      },
      "outputs": [],
      "source": [
        "def download_youtube_video(link, output_file):\n",
        "    yt = YouTube(link)\n",
        "    stream = yt.streams.get_highest_resolution()\n",
        "    stream.download(output_path='', filename=output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2R_njU2Uby7o"
      },
      "outputs": [],
      "source": [
        "def convert_to_wav(input_video, output_audio):\n",
        "    video_clip = VideoFileClip(input_video)\n",
        "    audio_clip = video_clip.audio\n",
        "    audio_clip.write_audiofile(output_audio, codec=\"pcm_s16le\")\n",
        "    audio_clip.close()\n",
        "    video_clip.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-yVf3GZb1I9"
      },
      "outputs": [],
      "source": [
        "def process_audio_for_transcription(audio_file):\n",
        "    waveform, sample_rate = torchaudio.load(audio_file)\n",
        "\n",
        "    # Convert to single-channel (mono) if the audio is multi-channel\n",
        "    if waveform.size(0) > 1:\n",
        "        # Take the average of the channels along the channel dimension (dim=0)\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "    # Resample the audio to the model's expected sample rate\n",
        "    resampler = Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "    resampled_waveform = resampler(waveform)\n",
        "\n",
        "    # Resample the waveform to the model's expected sample rate\n",
        "    resampled_audio = resampled_waveform.squeeze(0).numpy()\n",
        "\n",
        "    return resampled_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt92GdE1b3d9",
        "outputId": "39286d15-f030-4d35-d973-da67bf9746f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter YouTube video link: https://www.youtube.com/watch?v=n0NWsLoMWcs\n",
            "Video downloaded successfully.\n",
            "MoviePy - Writing audio in audio.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Audio converted to WAV format successfully.\n",
            "Transcription (Hindi): अगर � हाथ की लखी रोग नहीं बदलते दूर नहीं है तब आपके पास सब कुछ होगा लेकिन फिर भी अपना कुछ भी होने का डर नहीं\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    youtube_link = input(\"Enter YouTube video link: \")\n",
        "    video_file = \"video.mp4\"\n",
        "    audio_file = \"audio.wav\"\n",
        "    transcript = \"\"\n",
        "\n",
        "    try:\n",
        "        # Download the YouTube video\n",
        "        download_youtube_video(youtube_link, video_file)\n",
        "        print(\"Video downloaded successfully.\")\n",
        "\n",
        "        # Convert video to WAV format\n",
        "        convert_to_wav(video_file, audio_file)\n",
        "        print(\"Audio converted to WAV format successfully.\")\n",
        "\n",
        "        # Process audio for transcription\n",
        "        audio_data = process_audio_for_transcription(audio_file)\n",
        "\n",
        "        # Get audio length in seconds\n",
        "        audio_info = torchaudio.info(audio_file)\n",
        "        audio_length = audio_info.num_frames / audio_info.sample_rate\n",
        "\n",
        "        # Transcription\n",
        "        transcribe = pipeline(\n",
        "            task=\"automatic-speech-recognition\",\n",
        "            model=\"vasista22/whisper-hindi-small\",\n",
        "            chunk_length_s=audio_length,  # Set chunk_length_s equal to audio length\n",
        "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        transcribe.model.config.forced_decoder_ids = transcribe.tokenizer.get_decoder_prompt_ids(language=\"hi\", task=\"transcribe\")\n",
        "\n",
        "        print(\"Transcription (Hindi):\", transcribe(audio_data)[\"text\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2iTGn79b6Yy"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from pytube import YouTube\n",
        "from moviepy.editor import VideoFileClip\n",
        "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration\n",
        "import torchaudio\n",
        "from torchaudio.transforms import Resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLbSFzubqeKe"
      },
      "outputs": [],
      "source": [
        "def download_youtube_video(link, output_file):\n",
        "    yt = YouTube(link)\n",
        "    stream = yt.streams.get_highest_resolution()\n",
        "    stream.download(output_path='', filename=output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oTeTuevqh8A"
      },
      "outputs": [],
      "source": [
        "def convert_to_wav(input_video, output_audio):\n",
        "    video_clip = VideoFileClip(input_video)\n",
        "    audio_clip = video_clip.audio\n",
        "    audio_clip.write_audiofile(output_audio, codec=\"pcm_s16le\")\n",
        "    audio_clip.close()\n",
        "    video_clip.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTvP7rCbqjvr"
      },
      "outputs": [],
      "source": [
        "def process_audio_for_transcription(audio_file):\n",
        "    waveform, sample_rate = torchaudio.load(audio_file)\n",
        "\n",
        "    # Convert to single-channel (mono) if the audio is multi-channel\n",
        "    if waveform.size(0) > 1:\n",
        "        # Take the average of the channels along the channel dimension (dim=0)\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "    # Resample the audio to the model's expected sample rate\n",
        "    resampler = Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "    resampled_waveform = resampler(waveform)\n",
        "\n",
        "    # Resample the waveform to the model's expected sample rate\n",
        "    resampled_audio = resampled_waveform.squeeze(0).numpy()\n",
        "\n",
        "    return resampled_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWhft9OwrL8M"
      },
      "outputs": [],
      "source": [
        "def summarize_hindi_transcription(transcription):\n",
        "    # Load the T5 tokenizer and model\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "    # Prepare the input\n",
        "    input_text = \"summarize: \" + transcription\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "\n",
        "    # Generate the summary\n",
        "    summary_ids = model.generate(inputs, num_beams=4, min_length=30, max_length=150, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyv0Bs9YrO_J",
        "outputId": "9905751b-21a6-4865-fb4c-7f76d9ab8455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter YouTube video link: https://www.youtube.com/watch?v=n0NWsLoMWcs\n",
            "Video downloaded successfully.\n",
            "MoviePy - Writing audio in audio.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Audio converted to WAV format successfully.\n",
            "Transcription (Hindi): अगर � हाथ की लखी रोग नहीं बदलते दूर नहीं है तब आपके पास सब कुछ होगा लेकिन फिर भी अपना कुछ भी होने का डर नहीं\n",
            "An error occurred: \n",
            "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\n",
            "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
            "that match your environment. Please note that you may need to restart your runtime after installation.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    youtube_link = input(\"Enter YouTube video link: \")\n",
        "    video_file = \"video.mp4\"\n",
        "    audio_file = \"audio.wav\"\n",
        "    transcript = \"\"\n",
        "\n",
        "    try:\n",
        "        # Download the YouTube video\n",
        "        download_youtube_video(youtube_link, video_file)\n",
        "        print(\"Video downloaded successfully.\")\n",
        "\n",
        "        # Convert video to WAV format\n",
        "        convert_to_wav(video_file, audio_file)\n",
        "        print(\"Audio converted to WAV format successfully.\")\n",
        "\n",
        "        # Process audio for transcription\n",
        "        audio_data = process_audio_for_transcription(audio_file)\n",
        "\n",
        "        # Transcription\n",
        "        transcribe = pipeline(\n",
        "            task=\"automatic-speech-recognition\",\n",
        "            model=\"vasista22/whisper-hindi-small\",\n",
        "            chunk_length_s=audio_length,  # Set chunk_length_s equal to audio length\n",
        "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        transcribe.model.config.forced_decoder_ids = transcribe.tokenizer.get_decoder_prompt_ids(language=\"hi\", task=\"transcribe\")\n",
        "\n",
        "        hindi_transcription = transcribe(audio_data)[\"text\"]\n",
        "        print(\"Transcription (Hindi):\", hindi_transcription)\n",
        "\n",
        "        # Summarization\n",
        "        summarized_text = summarize_hindi_transcription(hindi_transcription)\n",
        "\n",
        "        print(\"Summarized Text:\")\n",
        "        print(summarized_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZj-ct0jrSpv",
        "outputId": "77020b79-b422-4b79-9e6b-eef1784177dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "awe-3DZsuAAX",
        "outputId": "ad31e2cf-a28c-4c04-a099-7893868ff6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video downloaded successfully.\n",
            "MoviePy - Writing audio in audio.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Audio converted to WAV format successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcription (Hindi): मैं कहां से खराब आए और हम सबने कहा कि आपकी प्रॉब्लम नहीं है हम सबकी प्रॉब्छा होता है परचे बनवाए थे अपने फ्रेंड में रिलेटेज में यहाँ पे वहाँ पे देते थे वो इतन� नहीं � यहाँ से तीसरी सीट पर बैठा हुई लाख � हूँदो दो लाख के चेक ऐैं पागल हो लेकर के जाता था वो मेरा और ज्यादा मजाक उठाते अब ये जो मैं फेल हुआ वो मेरी अच्छेमेरे को मेरे रिलेटिव ने फैमिली मेंऔरखादू तो आपको हँसते पेड़ दर्ज हो जाएपनी सक्सेस की वजह सीखनी है मुझे फोटोग्राफ आती है ना तो लाइफ में कभी न कभी ऐसी स्टेज आएगी आप लोग लाइफ में आप उठा लोगे एक्शन ले लोगे और जो आप चाहते हो वो जाकर रियलिटी से टकराएगा जो बहुत अलग ह�इंट था कि मेरे फेलियर मेरी सक्सेस कैसे एक छोटी सी ऐड निकाली न्यूजझेअपनी पहली आइड द्टी बहुद प्रिंटर को थोड़ा सा एडवां के साथ निकल गया\n",
            "An error occurred: \n",
            "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\n",
            "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
            "that match your environment. Please note that you may need to restart your runtime after installation.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    youtube_link = input(\"Enter YouTube video link: \")\n",
        "    video_file = \"video.mp4\"\n",
        "    audio_file = \"audio.wav\"\n",
        "    transcript = \"\"\n",
        "\n",
        "    try:\n",
        "        # Download the YouTube video\n",
        "        download_youtube_video(youtube_link, video_file)\n",
        "        print(\"Video downloaded successfully.\")\n",
        "\n",
        "        # Convert video to WAV format\n",
        "        convert_to_wav(video_file, audio_file)\n",
        "        print(\"Audio converted to WAV format successfully.\")\n",
        "\n",
        "        # Process audio for transcription\n",
        "        audio_data = process_audio_for_transcription(audio_file)\n",
        "\n",
        "        # Transcription\n",
        "        transcribe = pipeline(\n",
        "            task=\"automatic-speech-recognition\",\n",
        "            model=\"vasista22/whisper-hindi-small\",\n",
        "            chunk_length_s=audio_length,  # Set chunk_length_s equal to audio length\n",
        "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        transcribe.model.config.forced_decoder_ids = transcribe.tokenizer.get_decoder_prompt_ids(language=\"hi\", task=\"transcribe\")\n",
        "        # (Code remains the same)\n",
        "\n",
        "        # Transcription\n",
        "        # (Code remains the same)\n",
        "\n",
        "        print(\"Transcription (Hindi):\", transcribe(audio_data)[\"text\"])\n",
        "\n",
        "        # Summarization\n",
        "        hindi_transcription = transcribe(audio_data)[\"text\"]\n",
        "        summarized_text = summarize_hindi_transcription(hindi_transcription)\n",
        "\n",
        "        print(\"Summarized Text:\")\n",
        "        print(summarized_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VjQCsTjYuQVQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from pytube import YouTube\n",
        "from moviepy.editor import VideoFileClip\n",
        "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration\n",
        "import torchaudio\n",
        "from torchaudio.transforms import Resample\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, processors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_youtube_video(link, output_file):\n",
        "    yt = YouTube(link)\n",
        "    stream = yt.streams.get_highest_resolution()\n",
        "    stream.download(output_path='', filename=output_file)"
      ],
      "metadata": {
        "id": "SD7uBO42DkcS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_wav(input_video, output_audio):\n",
        "    video_clip = VideoFileClip(input_video)\n",
        "    audio_clip = video_clip.audio\n",
        "    audio_clip.write_audiofile(output_audio, codec=\"pcm_s16le\")\n",
        "    audio_clip.close()\n",
        "    video_clip.close()"
      ],
      "metadata": {
        "id": "Y73AmxLgDsJC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_for_transcription(audio_file):\n",
        "    waveform, sample_rate = torchaudio.load(audio_file)\n",
        "\n",
        "    # Convert to single-channel (mono) if the audio is multi-channel\n",
        "    if waveform.size(0) > 1:\n",
        "        # Take the average of the channels along the channel dimension (dim=0)\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "    # Resample the audio to the model's expected sample rate\n",
        "    resampler = Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "    resampled_waveform = resampler(waveform)\n",
        "\n",
        "    # Resample the waveform to the model's expected sample rate\n",
        "    resampled_audio = resampled_waveform.squeeze(0).numpy()\n",
        "\n",
        "    return resampled_audio"
      ],
      "metadata": {
        "id": "STzvmQM0Du4l"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "def summarize_hindi_transcription(transcription):\n",
        "    # Load the T5 tokenizer and model\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "    # Prepare the input\n",
        "    input_text = \"summarize: \" + transcription\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "\n",
        "    # Generate the summary\n",
        "    summary_ids = model.generate(inputs, num_beams=4, min_length=30, max_length=150, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "CArky6jsDxVV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    youtube_link = input(\"Enter YouTube video link: \")\n",
        "    video_file = \"video.mp4\"\n",
        "    audio_file = \"audio.wav\"\n",
        "    transcript = \"\"\n",
        "\n",
        "    try:\n",
        "      # Download the YouTube video\n",
        "        download_youtube_video(youtube_link, video_file)\n",
        "        print(\"Video downloaded successfully.\")\n",
        "\n",
        "        # Convert video to WAV format\n",
        "        convert_to_wav(video_file, audio_file)\n",
        "        print(\"Audio converted to WAV format successfully.\")\n",
        "\n",
        "        # Process audio for transcription\n",
        "        audio_data = process_audio_for_transcription(audio_file)\n",
        "\n",
        "        # Transcription\n",
        "        transcribe = pipeline(\n",
        "            task=\"automatic-speech-recognition\",\n",
        "            model=\"vasista22/whisper-hindi-small\",\n",
        "            chunk_length_s=audio_length,  # Set chunk_length_s equal to audio length\n",
        "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        transcribe.model.config.forced_decoder_ids = transcribe.tokenizer.get_decoder_prompt_ids(language=\"hi\", task=\"transcribe\")\n",
        "        # (Code remains the same)\n",
        "\n",
        "        # Transcription\n",
        "        # (Code remains the same)\n",
        "        # (Code remains the same)\n",
        "\n",
        "        # Transcription\n",
        "        # (Code remains the same)\n",
        "\n",
        "        print(\"Transcription (Hindi):\", transcribe(audio_data)[\"text\"])\n",
        "\n",
        "        # Summarization\n",
        "        hindi_transcription = transcribe(audio_data)[\"text\"]\n",
        "        summarized_text = summarize_hindi_transcription(hindi_transcription)\n",
        "\n",
        "        print(\"Summarized Text:\")\n",
        "        print(summarized_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTbOgJrrD1Cr",
        "outputId": "62a21014-4fe6-47b5-82f6-47727362bcda"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter YouTube video link: https://www.youtube.com/watch?v=MgWrHsRaMv0\n",
            "Video downloaded successfully.\n",
            "MoviePy - Writing audio in audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Audio converted to WAV format successfully.\n",
            "Transcription (Hindi): मैं कहां से खराब आए और हम सबने कहा कि आपकी प्रॉब्लम नहीं है हम सबकी प्रॉब्छा होता है परचे बनवाए थे अपने फ्रेंड में रिलेटेज में यहाँ पे वहाँ पे देते थे वो इतन� नहीं � यहाँ से तीसरी सीट पर बैठा हुई लाख � हूँदो दो लाख के चेक ऐैं पागल हो लेकर के जाता था वो मेरा और ज्यादा मजाक उठाते अब ये जो मैं फेल हुआ वो मेरी अच्छेमेरे को मेरे रिलेटिव ने फैमिली मेंऔरखादू तो आपको हँसते पेड़ दर्ज हो जाएपनी सक्सेस की वजह सीखनी है मुझे फोटोग्राफ आती है ना तो लाइफ में कभी न कभी ऐसी स्टेज आएगी आप लोग लाइफ में आप उठा लोगे एक्शन ले लोगे और जो आप चाहते हो वो जाकर रियलिटी से टकराएगा जो बहुत अलग ह�इंट था कि मेरे फेलियर मेरी सक्सेस कैसे एक छोटी सी ऐड निकाली न्यूजझेअपनी पहली आइड द्टी बहुद प्रिंटर को थोड़ा सा एडवां के साथ निकल गया\n",
            "An error occurred: \n",
            "T5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\n",
            "installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\n",
            "that match your environment. Please note that you may need to restart your runtime after installation.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wlkpA3jtEMxB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}